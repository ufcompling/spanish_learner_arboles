{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liu.ying/Spaceship/learner_spanish_depparse/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CoNLL-U format\n",
    "def conll_read_sentence(file_handle):\n",
    "\tsent = []\n",
    "\tfor line in file_handle:\n",
    "\t\tline = line.strip('\\n')\n",
    "\t\tif not line.startswith('#'):\n",
    "\t\t\ttoks = line.split(\"\\t\")\n",
    "\t\t#\tif len(toks) == 10 and '-' not in toks[0] and '.' not in toks[0]:\n",
    "\t\t\tif len(toks) == 10 and '.' not in toks[0]:\n",
    "\t\t\t\tif toks[0] == 'q1':\n",
    "\t\t\t\t\ttoks[0] = '1'\n",
    "\t\t\t\tif toks[7] == 'ROOT':\n",
    "\t\t\t\t\ttoks[7] = 'root'\n",
    "\t\t\t\tsent.append(toks)\n",
    "\t\t\telif sent:\n",
    "\t\t\t\tfor w in sent:\n",
    "\t\t\t\t\tif '-' in w[0]:\n",
    "\t\t\t\t\t\tsent.remove(w)\n",
    "\t\t\t\tyield sent\n",
    "\t\t\t\tsent = []\n",
    "\tif sent:\n",
    "\t\tyield sent  # Ensure the last sentence is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect meta information including doc id and sent id\n",
    "def collect_meta(file_handle):\n",
    "    doc_meta_list = []\n",
    "    sent_meta_list = []\n",
    "    with open(file_handle, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            if line.startswith('# doc_id'):\n",
    "                doc_meta_list.append(line.split(' = ')[1])\n",
    "            if line.startswith('# sent_id'):\n",
    "                sent_meta_list.append(line.split(' = ')[1])\n",
    "    return doc_meta_list, sent_meta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect dependency annotations from a given *.conllu file\n",
    "def dependency_annotations(file_handle):\n",
    "    doc_meta_list, sent_meta_list = collect_meta(file_handle)\n",
    "    trees = []\n",
    "    all_sents = []\n",
    "    pos_annotations = []\n",
    "    head_annotations = []\n",
    "    deprel_annotations = []\n",
    "    both_annotations = []\n",
    "    \n",
    "    with open(file_handle) as f:\n",
    "        trees = list(conll_read_sentence(f))\n",
    "        for sent in trees:\n",
    "            all_sents.append(sent)\n",
    "            pos_annotations.append([tok[3] for tok in sent])\n",
    "            head_annotations.append([tok[6] for tok in sent])\n",
    "            deprel_annotations.append([tok[7] for tok in sent])\n",
    "            both_annotations.append([tok[6] + '_' + tok[7] for tok in sent])\n",
    "    \n",
    "    return doc_meta_list, sent_meta_list, all_sents, pos_annotations, head_annotations, deprel_annotations, both_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator1_file = '../random_trees_inter_annotator.conllu'\n",
    "annotator2_file = '../rpugh-annotated_random_iaa.conllu'\n",
    "\n",
    "doc_meta_list1, sent_meta_list1, all_sents1, pos_annotations1, head_annotations1, deprel_annotations1, both_annotations1 = dependency_annotations(annotator1_file)\n",
    "doc_meta_list2, sent_meta_list2, all_sents2, pos_annotations2, head_annotations2, deprel_annotations2, both_annotations2 = dependency_annotations(annotator2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(doc_meta_list1)):\n",
    "    if doc_meta_list1[i] != doc_meta_list2[i]:\n",
    "        print('Document meta information does not match')\n",
    "        print(i, doc_meta_list1[i], doc_meta_list2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tag agreement: 0.98\n",
      "Syntactic head agreement: 0.93\n",
      "Syntactic deprel agreement: 0.91\n",
      "Syntactic both agreement: 0.88\n"
     ]
    }
   ],
   "source": [
    "## Loop through each sentence and compare the dependencies\n",
    "overall_pos_agree_score = []\n",
    "overall_head_agree_score = []\n",
    "overall_deprel_agree_score = []\n",
    "overall_both_agree_score = []\n",
    "\n",
    "def compute_agree_score(annotation_list1, annotation_list2):\n",
    "    overall_agree_score = 0\n",
    "    for i in range(len(annotation_list1)):\n",
    "        agree_score = 0\n",
    "        annotation1 = annotation_list1[i]\n",
    "        annotation2 = annotation_list2[i]\n",
    "        for z in range(len(annotation1)):\n",
    "            if annotation1[z] == annotation2[z]:\n",
    "                agree_score += 1\n",
    "        overall_agree_score += agree_score / len(annotation1)\n",
    "    return round(overall_agree_score / len(annotation_list1), 2)\n",
    "\n",
    "print('POS tag agreement:', compute_agree_score(pos_annotations1, pos_annotations2))\n",
    "print('Syntactic head agreement:', compute_agree_score(head_annotations1, head_annotations2))\n",
    "print('Syntactic deprel agreement:', compute_agree_score(deprel_annotations1, deprel_annotations2))\n",
    "print('Syntactic both agreement:', compute_agree_score(both_annotations1, both_annotations2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagree_doc_meta_list = []\n",
    "disagree_sent_meta_list = []\n",
    "disagree_sents = []\n",
    "for i in range(len(all_sents1)):\n",
    "    sent1 = all_sents1[i]\n",
    "    sent2 = all_sents2[i]\n",
    "    if sent1 != sent2:\n",
    "        disagree_doc_meta_list.append(doc_meta_list1[i])\n",
    "        disagree_sent_meta_list.append(sent_meta_list1[i])\n",
    "        new_sent = []\n",
    "        for z in range(len(sent1)):\n",
    "            tok = sent1[z]\n",
    "            tok[6] = sent1[z][6] + '|' + sent2[z][6]\n",
    "            tok[7] = sent1[z][7] + '|' + sent2[z][7]\n",
    "            new_sent.append(tok)\n",
    "\n",
    "        disagree_sents.append(new_sent)\n",
    "        words = ' '.join([tok[1] for tok in new_sent])\n",
    "\n",
    "with open('../disagree_sents.conllu', 'w') as f:\n",
    "    for i in range(len(disagree_sents)):\n",
    "        doc_meta = disagree_doc_meta_list[i]\n",
    "        sent_meta = disagree_sent_meta_list[i]\n",
    "        f.write(doc_meta + '\\n')\n",
    "        f.write(sent_meta + '\\n')\n",
    "        \n",
    "        sent = disagree_sents[i]\n",
    "        for tok in sent:\n",
    "            f.write('\\t'.join(tok) + '\\n')\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 48\n",
      "Total number of tokens: 805\n"
     ]
    }
   ],
   "source": [
    "## Descriptive statistics for the cross_annotated conllu file\n",
    "num_sents = 0\n",
    "num_tokens = 0\n",
    "with open('../random_trees_inter_annotator.conllu') as f:\n",
    "    trees = list(conll_read_sentence(f))\n",
    "    num_sents = len(trees)\n",
    "    for sent in trees:\n",
    "        num_tokens += len(sent)\n",
    "\n",
    "print('Total number of sentences:', num_sents)\n",
    "print('Total number of tokens:', num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 383\n",
      "Total number of unique sentences 383\n"
     ]
    }
   ],
   "source": [
    "## Checking for duplicates\n",
    "trees = []\n",
    "num_sents = 0\n",
    "\n",
    "with open('../all_random_sents_new_sentid.conllu') as f:\n",
    "    trees = list(conll_read_sentence(f))\n",
    "    num_sents = len(trees)\n",
    "\n",
    "print('Total number of sentences:', num_sents)\n",
    "print('Total number of unique sentences', len(trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
